{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2be3fbb-0e7a-44c2-8807-381e580db097",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-04 11:34:19.929692: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-04 11:34:20.155070: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-04 11:34:21.411377: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-04 11:34:24.269686: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57ec340f-ef96-4940-9e89-a8be6c17a3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_lengths = []\n",
    "median_token_counts = []\n",
    "columns = []\n",
    "target = []\n",
    "average_numeric_counts = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77dc0c11-e811-4540-9a74-c29dd551b55f",
   "metadata": {},
   "source": [
    "## Round1_T2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06dfe186-559d-4a4b-a568-eacafc41f377",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# READ THE JSON\n",
    "#####################\n",
    "\n",
    "json_file_path = \"./data/Round1_T2D_f3_sorted_mentions.json\"\n",
    "\n",
    "# Load the JSON file\n",
    "with open(json_file_path, \"r\") as file:\n",
    "    R1_sorted_mentions = json.load(file)\n",
    "\n",
    "R1_cea = [item[0]for item in R1_sorted_mentions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab481172-9273-43e5-b4d2-d1011cec6e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [01:45<00:00,  1.64s/it]\n"
     ]
    }
   ],
   "source": [
    "tables = \"./data/Dataset/Dataset/Round1_T2D/tables/\"\n",
    "\n",
    "def count_numbers_in_string(s):\n",
    "    count = 0\n",
    "    for item in s:\n",
    "        count += len(re.findall(r'\\d+', str(item)))\n",
    "    return count\n",
    "            \n",
    "# Iterate through each table\n",
    "for table in tqdm(os.listdir(tables)):\n",
    "    table_file = os.path.join(tables, table)\n",
    "    table_name = table.split(\".\")[0]\n",
    "    df = pd.read_csv(table_file)\n",
    "    \n",
    "    for col in range(df.shape[1]):\n",
    "        NE_flag = False\n",
    "        column = df.iloc[:, col].astype(str)\n",
    "        \n",
    "        # Calculate median length for the current column\n",
    "        median_lengths.append(column.apply(len).median())\n",
    "        \n",
    "        # Calculate median token count for the current column\n",
    "        median_token_counts.append(column.apply(lambda x: len(str(x).split())).median())\n",
    "        \n",
    "        # Calculate average count of numeric values in the current column\n",
    "        total_numeric_count = column.apply(count_numbers_in_string).sum()\n",
    "        average_numeric_count = total_numeric_count / df.shape[0] if df.shape[0] > 0 else 0\n",
    "        average_numeric_counts.append(average_numeric_count)\n",
    "        \n",
    "        for row in range(df.shape[0]):\n",
    "            cell_value = df.iloc[row, col]\n",
    "            if cell_value in R1_cea:    # if the column has at least one item in cea is a NE\n",
    "                target.append(\"NE\")\n",
    "                NE_flag = True\n",
    "                break\n",
    "\n",
    "        if NE_flag: \n",
    "            continue\n",
    "        \n",
    "        if column.apply(len).mean() - average_numeric_count < 2:   # if there are only 2 characters at most\n",
    "            target.append(\"lit\")\n",
    "        else:\n",
    "            target.append(\"None\")\n",
    "    \n",
    "    columns = columns + df.columns.tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8408542e-7a90-4b4b-b1a8-74fc2448eed5",
   "metadata": {},
   "source": [
    "## Round3_2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2da63443-b6a5-4060-b097-e6e4a2fb9e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# READ THE JSON\n",
    "#####################\n",
    "\n",
    "json_file_path = \"./data/Round3_2019_sorted_mentions.json\"\n",
    "\n",
    "# Load the JSON file\n",
    "with open(json_file_path, \"r\") as file:\n",
    "    R3_sorted_mentions = json.load(file)\n",
    "\n",
    "R3_cea = [item[0]for item in R3_sorted_mentions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081c261e-3ff1-41ca-8cde-34c090d858e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 114/2162 [31:31<23:59:22, 42.17s/it]"
     ]
    }
   ],
   "source": [
    "tables = \"./data/Dataset/Dataset/Round3_2019/tables/\"\n",
    "\n",
    "def count_numbers_in_string(s):\n",
    "    count = 0\n",
    "    for item in s:\n",
    "        count += len(re.findall(r'\\d+', str(item)))\n",
    "    return count\n",
    "            \n",
    "# Iterate through each table\n",
    "for table in tqdm(os.listdir(tables)):\n",
    "    table_file = os.path.join(tables, table)\n",
    "    table_name = table.split(\".\")[0]\n",
    "    df = pd.read_csv(table_file)\n",
    "    \n",
    "    for col in range(df.shape[1]):\n",
    "        NE_flag = False\n",
    "        column = df.iloc[:, col].astype(str)\n",
    "        \n",
    "        # Calculate median length for the current column\n",
    "        median_lengths.append(column.apply(len).median())\n",
    "        \n",
    "        # Calculate median token count for the current column\n",
    "        median_token_counts.append(column.apply(lambda x: len(str(x).split())).median())\n",
    "        \n",
    "        # Calculate average count of numeric values in the current column\n",
    "        total_numeric_count = column.apply(count_numbers_in_string).sum()\n",
    "        average_numeric_count = total_numeric_count / df.shape[0] if df.shape[0] > 0 else 0\n",
    "        average_numeric_counts.append(average_numeric_count)\n",
    "        \n",
    "        for row in range(df.shape[0]):\n",
    "            cell_value = df.iloc[row, col]\n",
    "            if cell_value in R3_cea:    # if the column has at least one item in cea is a NE\n",
    "                target.append(\"NE\")\n",
    "                NE_flag = True\n",
    "                break\n",
    "\n",
    "        if NE_flag: \n",
    "            continue\n",
    "        \n",
    "        if column.apply(len).mean() - average_numeric_count < 2:   # if there are only 2 characters at most\n",
    "            target.append(\"lit\")\n",
    "        else:\n",
    "            target.append(\"None\")\n",
    "    \n",
    "    columns = columns + df.columns.tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673eea67-ad8c-4b23-99ef-c5f2dc86b1cc",
   "metadata": {},
   "source": [
    "## 2T_Round4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778c0a1c-045b-4cc6-ac29-d60215b8fefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# READ THE JSON\n",
    "#####################\n",
    "\n",
    "json_file_path = \"./data/2T_Round4_sorted_mentions.json\"\n",
    "\n",
    "# Load the JSON file\n",
    "with open(json_file_path, \"r\") as file:\n",
    "    R4_sorted_mentions = json.load(file)\n",
    "\n",
    "R4_2T_cea = [item[0]for item in R4_sorted_mentions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcf378a-2f88-44c0-a551-843d7dc9bed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = \"./data/Dataset/Dataset/2T_2020/tables/\"\n",
    "\n",
    "def count_numbers_in_string(s):\n",
    "    count = 0\n",
    "    for item in s:\n",
    "        count += len(re.findall(r'\\d+', str(item)))\n",
    "    return count\n",
    "            \n",
    "# Iterate through each table\n",
    "for table in tqdm(os.listdir(tables)):\n",
    "    table_file = os.path.join(tables, table)\n",
    "    table_name = table.split(\".\")[0]\n",
    "    df = pd.read_csv(table_file)\n",
    "    \n",
    "    for col in range(df.shape[1]):\n",
    "        NE_flag = False\n",
    "        column = df.iloc[:, col].astype(str)\n",
    "        \n",
    "        # Calculate median length for the current column\n",
    "        median_lengths.append(column.apply(len).median())\n",
    "        \n",
    "        # Calculate median token count for the current column\n",
    "        median_token_counts.append(column.apply(lambda x: len(str(x).split())).median())\n",
    "        \n",
    "        # Calculate average count of numeric values in the current column\n",
    "        total_numeric_count = column.apply(count_numbers_in_string).sum()\n",
    "        average_numeric_count = total_numeric_count / df.shape[0] if df.shape[0] > 0 else 0\n",
    "        average_numeric_counts.append(average_numeric_count)\n",
    "        \n",
    "        for row in range(df.shape[0]):\n",
    "            cell_value = df.iloc[row, col]\n",
    "            if cell_value in R4_2T_cea:    # if the column has at least one item in cea is a NE\n",
    "                target.append(\"NE\")\n",
    "                NE_flag = True\n",
    "                break\n",
    "\n",
    "        if NE_flag: \n",
    "            continue\n",
    "        \n",
    "        if column.apply(len).mean() - average_numeric_count < 2:   # if there are only 2 characters at most\n",
    "            target.append(\"lit\")\n",
    "        else:\n",
    "            target.append(\"None\")\n",
    "    \n",
    "    columns = columns + df.columns.tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56a4ed1-7939-4dfc-9eb4-9c9c0f102ef4",
   "metadata": {},
   "source": [
    "## Round4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208edf55-99eb-4018-a0a7-031dbd192a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# READ THE JSON\n",
    "#####################\n",
    "\n",
    "json_file_path = \"./data/Round4_sorted_mentions.json\"\n",
    "\n",
    "# Load the JSON file\n",
    "with open(json_file_path, \"r\") as file:\n",
    "    R4_sorted_mentions = json.load(file)\n",
    "\n",
    "R4_cea = [item[0]for item in R4_sorted_mentions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b461089-7f54-4ed5-9aef-669855493e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = \"./data/Dataset/Dataset/Round4_2020/tables/\"\n",
    "\n",
    "def count_numbers_in_string(s):\n",
    "    count = 0\n",
    "    for item in s:\n",
    "        count += len(re.findall(r'\\d+', str(item)))\n",
    "    return count\n",
    "            \n",
    "# Iterate through each table\n",
    "for table in tqdm(os.listdir(tables)):\n",
    "    table_file = os.path.join(tables, table)\n",
    "    table_name = table.split(\".\")[0]\n",
    "    df = pd.read_csv(table_file)\n",
    "    \n",
    "    for col in range(df.shape[1]):\n",
    "        NE_flag = False\n",
    "        column = df.iloc[:, col].astype(str)\n",
    "        \n",
    "        # Calculate median length for the current column\n",
    "        median_lengths.append(column.apply(len).median())\n",
    "        \n",
    "        # Calculate median token count for the current column\n",
    "        median_token_counts.append(column.apply(lambda x: len(str(x).split())).median())\n",
    "        \n",
    "        # Calculate average count of numeric values in the current column\n",
    "        total_numeric_count = column.apply(count_numbers_in_string).sum()\n",
    "        average_numeric_count = total_numeric_count / df.shape[0] if df.shape[0] > 0 else 0\n",
    "        average_numeric_counts.append(average_numeric_count)\n",
    "        \n",
    "        for row in range(df.shape[0]):\n",
    "            cell_value = df.iloc[row, col]\n",
    "            if cell_value in R4_cea:    # if the column has at least one item in cea is a NE\n",
    "                target.append(\"NE\")\n",
    "                NE_flag = True\n",
    "                break\n",
    "\n",
    "        if NE_flag: \n",
    "            continue\n",
    "        \n",
    "        if column.apply(len).mean() - average_numeric_count < 2:   # if there are only 2 characters at most\n",
    "            target.append(\"lit\")\n",
    "        else:\n",
    "            target.append(\"None\")\n",
    "    \n",
    "    columns = columns + df.columns.tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af83a2d-7e99-4577-85ec-b297fdf376ad",
   "metadata": {},
   "source": [
    "## DF creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c14bf0-1ea7-4856-90a9-e433c1c807a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the DataFrame\n",
    "df_def = pd.DataFrame({\n",
    "    'column names': columns,\n",
    "    'median_lengths': median_lengths,\n",
    "    'median_token_counts': median_token_counts,\n",
    "    'average_numeric_counts': average_numeric_counts,\n",
    "    'target': target\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6c179f-5eb2-4c54-9d77-4639ddb9f601",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_def.to_csv('./data/NE_lit_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446e1e43-0b44-4204-b52a-80be8cce57fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "#   READ DIRECTLY THE DATASET HERE\n",
    "###################################\n",
    "\n",
    "df = pd.read_csv('./data/NE_lit_dataset.csv')\n",
    "filtered_df = df[df['target'].isin(['lit', 'NE'])]\n",
    "\n",
    "# Displaying the filtered DataFrame\n",
    "df[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001b29d6-834d-47ce-bbf7-eac0d736e9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_counts = df['target'].value_counts()\n",
    "\n",
    "# Extract counts for specific values\n",
    "ne_count = target_counts.get(\"NE\", 0)\n",
    "lit_count = target_counts.get(\"lit\", 0)\n",
    "none_count = df.shape[0] - (ne_count+lit_count)\n",
    "\n",
    "print(f\"Count of 'NE': {ne_count}\")\n",
    "print(f\"Count of 'lit': {lit_count}\")\n",
    "print(f\"Count of 'NaN': {none_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98b0060-e2de-4d00-a043-56bc1709897d",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2256078-4db3-4a4a-98c0-1e49c19b7fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the target variable to numeric\n",
    "label_encoder = LabelEncoder()\n",
    "filtered_df['target'] = label_encoder.fit_transform(filtered_df['target'])\n",
    "\n",
    "# One-hot encode the 'column names' column\n",
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "encoded_columns = one_hot_encoder.fit_transform(filtered_df[['column names']])\n",
    "\n",
    "# Combine the encoded categorical data with the numeric data\n",
    "numeric_data = filtered_df[['median_lengths', 'median_token_counts', 'average_numeric_counts']].values\n",
    "X = np.hstack([encoded_columns, numeric_data])\n",
    "y = filtered_df['target'].values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Input(shape=(X_train.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # Output layer with sigmoid activation for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {accuracy*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28204b07-3a07-4b09-8748-ec0d4f4eade7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Make predictions\n",
    "y_pred_probs = model.predict(X_test)\n",
    "y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "mapped_predictions = [\"lit\" if pred == 1 else \"NE\" for pred in y_pred.ravel()]\n",
    "\n",
    "# Extract the part of X_test that corresponds to the one-hot encoded columns\n",
    "encoded_columns_test = X_test[:, :encoded_columns.shape[1]]\n",
    "\n",
    "# Inverse transform the one-hot encoded columns to get the original categorical labels\n",
    "original_labels = one_hot_encoder.inverse_transform(encoded_columns_test)\n",
    "\n",
    "# Print a few examples to check\n",
    "for i in range(100):\n",
    "    print(f'Original label: {original_labels[i]}, Predicted: {mapped_predictions[i]}')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06397d40-ffd2-4fc2-a622-3a3338c45d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df[:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
